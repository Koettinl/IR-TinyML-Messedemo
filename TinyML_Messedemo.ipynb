{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TinyML_Messedemo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1lbXaYyTTk6y5ABUXFttj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Koettinl/IR-TinyML-Messedemo/blob/main/TinyML_Messedemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SHnM0t4R-FG"
      },
      "source": [
        "### Set Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjSYl52zRxMh",
        "outputId": "aa4bea1f-3734-4cd7-b8f9-7a709a9fa63e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfH55HWrR9Sc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d61498-27b6-4da2-b3d7-6ceed9843e49"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDeFYI_mR6x2"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "KtI6pTIdR5WA",
        "outputId": "701d6cc7-88db-4268-84f5-b0db7920b60c"
      },
      "source": [
        "# input data\n",
        "url = \"/content/drive/MyDrive/Colab Notebooks/messedemonstrator 3 states/klassifizierung_messedemo_261021.csv\"\n",
        "\n",
        "num_clases = 3\n",
        "# 8x8 image\n",
        "input = 64\n",
        "\n",
        "# read data set\n",
        "dataframe = pd.read_csv(url, parse_dates=True)\n",
        "h,w = dataframe.shape\n",
        "# separate date from data set\n",
        "dataframe.iloc[0:h, 0] = pd.to_datetime(dataframe.iloc[0:h,0])\n",
        "# Separate labels from the Data set\n",
        "'''df_labels = dataframe.iloc[0:h, w-1]'''\n",
        "df_label = dataframe.pop(dataframe.columns[w-1])\n",
        "df = dataframe.iloc[0:h, 1:w-1]\n",
        "\n",
        "# Visual representation\n",
        "\n",
        "row = 920 \n",
        "  #data = dataframe[row:row+1]\n",
        "data = df.iloc[row,0:w-1]\n",
        "data = np.array(data, dtype = np.float32 )\n",
        "size = int(np.sqrt(data.size))\n",
        "data = data.reshape(size, size)\n",
        "\n",
        "plt.imshow(data)\n",
        "plt.title('IR Image number: '+str(row)+' Label: '+str(df_label[row]))\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# prepare for NN\n",
        "min = df.min().min()\n",
        "max = df.max().max()\n",
        "print(\"Min: \", min,\"째C\\tMax: \", max, \"째C\")\n",
        "\n",
        "df_normalized = (dataframe.iloc[0:h, 1:w-1] - min) / (max - min)\n",
        "print(df.head())\n",
        "print(df_normalized.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min:  18.25 째C\tMax:  64.0 째C\n",
            "   19.25  19.75   20.5     20  20.5.1  ...  20.25.2   21.4  20.25.3  21.5.2  21.25.6\n",
            "0  20.25  20.25  20.50  19.25   20.50  ...    20.50  20.50    19.75   20.75    21.75\n",
            "1  20.25  20.25  20.75  20.00   20.75  ...    20.50  20.75    20.25   20.75    22.00\n",
            "2  20.50  20.25  20.00  19.75   20.50  ...    20.75  20.75    20.75   21.50    22.25\n",
            "3  20.50  20.25  20.50  20.00   20.50  ...    21.00  21.25    20.75   21.50    22.00\n",
            "4  20.25  19.75  20.50  19.75   20.50  ...    21.00  20.75    20.75   21.25    22.25\n",
            "\n",
            "[5 rows x 64 columns]\n",
            "      19.25     19.75      20.5  ...   20.25.3    21.5.2   21.25.6\n",
            "0  0.043716  0.043716  0.049180  ...  0.032787  0.054645  0.076503\n",
            "1  0.043716  0.043716  0.054645  ...  0.043716  0.054645  0.081967\n",
            "2  0.049180  0.043716  0.038251  ...  0.054645  0.071038  0.087432\n",
            "3  0.049180  0.043716  0.049180  ...  0.054645  0.071038  0.081967\n",
            "4  0.043716  0.032787  0.049180  ...  0.054645  0.065574  0.087432\n",
            "\n",
            "[5 rows x 64 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q83s-2r1Wbpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8e7e69-ef5e-47cf-9cb7-684fafb21112"
      },
      "source": [
        "# Set training and test data and labels\n",
        "training_dataset = df_normalized.sample(frac=0.8, random_state=0)\n",
        "testing_dataset =  df_normalized.drop(training_dataset.index)\n",
        "#training_dataset = np.expand_dims(training_dataset, axis=0)\n",
        "\n",
        "# reshape training dataset to a 8x8 np.array\n",
        "training_h, training_w = training_dataset.shape\n",
        "training_dataset = np.array(training_dataset, dtype=np.float32)\n",
        "training_dataset = training_dataset.reshape(training_h, size, size,-1)\n",
        "#training_dataset = np.expand_dims(training_dataset, 0)\n",
        "\n",
        "# reshape testing dataset to a 8x8 np.array\n",
        "testing_h, testing_w = testing_dataset.shape\n",
        "testing_dataset = np.array(testing_dataset, dtype=np.float32)\n",
        "testing_dataset = testing_dataset.reshape(testing_h, size, size,-1)\n",
        "#testing_dataset = np.expand_dims(testing_dataset, 0)\n",
        "print(testing_dataset.shape)\n",
        "\n",
        "# training and test labeling\n",
        "training_labels = df_label.sample(frac=0.8, random_state=0)\n",
        "testing_labels =  df_label.drop(training_labels.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1073, 8, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP38amirEQOD"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyKhGhJZEcST",
        "outputId": "d21e09a3-3a7e-46f4-d99a-e7682d08a562"
      },
      "source": [
        "batchsize = 32\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "#model.add(layers.Conv2D(16, (3,3), activation='sigmoid', input_shape=(8,8,1)))\n",
        "model.add(layers.Flatten(input_shape=(8,8,1))) #input_shape=(8,8,1)\n",
        "model.add(layers.Dense(32, activation= 'sigmoid',input_shape=(64,)))\n",
        "model.add(layers.Dense(16,activation= 'sigmoid'))\n",
        "model.add(layers.Dense(num_clases, activation= 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 2,659\n",
            "Trainable params: 2,659\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktQC5qprJyHG",
        "outputId": "c9b1edef-2fd9-4e13-f33b-52d10c86854c"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate= 0.005, momentum=0.9), loss = 'categorical_crossentropy', metrics = ['accuracy'],)\n",
        "    #optimizer=Adam(learning_rate= 0.00005), loss = 'categorical_crossentropy', metrics = ['accuracy'],)\n",
        "\n",
        "history = model.fit(training_dataset, \n",
        "                    to_categorical(training_labels), \n",
        "                    validation_data=(testing_dataset, testing_labels), \n",
        "                    validation_split=0.2, epochs = 500, batch_size = batchsize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 1.0958 - accuracy: 0.3727 - val_loss: 1.0760 - val_accuracy: 0.3970\n",
            "Epoch 2/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 1.0757 - accuracy: 0.4808 - val_loss: 1.0629 - val_accuracy: 0.5867\n",
            "Epoch 3/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 1.0588 - accuracy: 0.5318 - val_loss: 1.0351 - val_accuracy: 0.3970\n",
            "Epoch 4/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 1.0337 - accuracy: 0.5399 - val_loss: 1.0046 - val_accuracy: 0.4307\n",
            "Epoch 5/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.9971 - accuracy: 0.6434 - val_loss: 0.9647 - val_accuracy: 0.7322\n",
            "Epoch 6/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.9466 - accuracy: 0.6774 - val_loss: 0.9006 - val_accuracy: 0.7020\n",
            "Epoch 7/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.8847 - accuracy: 0.7369 - val_loss: 0.8319 - val_accuracy: 0.7544\n",
            "Epoch 8/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.8148 - accuracy: 0.8071 - val_loss: 0.7636 - val_accuracy: 0.8126\n",
            "Epoch 9/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 0.8065 - val_loss: 0.7015 - val_accuracy: 0.8242\n",
            "Epoch 10/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.8065 - val_loss: 0.6459 - val_accuracy: 0.8231\n",
            "Epoch 11/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.8121 - val_loss: 0.6023 - val_accuracy: 0.8324\n",
            "Epoch 12/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.8176 - val_loss: 0.5648 - val_accuracy: 0.8219\n",
            "Epoch 13/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.8237 - val_loss: 0.5367 - val_accuracy: 0.8440\n",
            "Epoch 14/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.8441 - val_loss: 0.5055 - val_accuracy: 0.8498\n",
            "Epoch 15/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8485 - val_loss: 0.4913 - val_accuracy: 0.8556\n",
            "Epoch 16/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8587 - val_loss: 0.4598 - val_accuracy: 0.8661\n",
            "Epoch 17/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8666 - val_loss: 0.4406 - val_accuracy: 0.8731\n",
            "Epoch 18/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8706 - val_loss: 0.4203 - val_accuracy: 0.8836\n",
            "Epoch 19/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8759 - val_loss: 0.3984 - val_accuracy: 0.8859\n",
            "Epoch 20/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8788 - val_loss: 0.3801 - val_accuracy: 0.8952\n",
            "Epoch 21/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8834 - val_loss: 0.3611 - val_accuracy: 0.9010\n",
            "Epoch 22/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8864 - val_loss: 0.3486 - val_accuracy: 0.9022\n",
            "Epoch 23/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8916 - val_loss: 0.3227 - val_accuracy: 0.9115\n",
            "Epoch 24/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8957 - val_loss: 0.3049 - val_accuracy: 0.9150\n",
            "Epoch 25/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8974 - val_loss: 0.2896 - val_accuracy: 0.9150\n",
            "Epoch 26/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.3139 - accuracy: 0.9009 - val_loss: 0.2753 - val_accuracy: 0.9255\n",
            "Epoch 27/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9021 - val_loss: 0.2602 - val_accuracy: 0.9255\n",
            "Epoch 28/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.9050 - val_loss: 0.2472 - val_accuracy: 0.9336\n",
            "Epoch 29/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.9085 - val_loss: 0.2336 - val_accuracy: 0.9325\n",
            "Epoch 30/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9111 - val_loss: 0.2279 - val_accuracy: 0.9348\n",
            "Epoch 31/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9143 - val_loss: 0.2152 - val_accuracy: 0.9371\n",
            "Epoch 32/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9181 - val_loss: 0.2083 - val_accuracy: 0.9360\n",
            "Epoch 33/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9181 - val_loss: 0.2041 - val_accuracy: 0.9360\n",
            "Epoch 34/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9202 - val_loss: 0.1941 - val_accuracy: 0.9406\n",
            "Epoch 35/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2246 - accuracy: 0.9222 - val_loss: 0.1876 - val_accuracy: 0.9395\n",
            "Epoch 36/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.9237 - val_loss: 0.1844 - val_accuracy: 0.9371\n",
            "Epoch 37/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9254 - val_loss: 0.1781 - val_accuracy: 0.9430\n",
            "Epoch 38/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9274 - val_loss: 0.1798 - val_accuracy: 0.9406\n",
            "Epoch 39/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2036 - accuracy: 0.9295 - val_loss: 0.1716 - val_accuracy: 0.9499\n",
            "Epoch 40/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9327 - val_loss: 0.1682 - val_accuracy: 0.9418\n",
            "Epoch 41/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9330 - val_loss: 0.1612 - val_accuracy: 0.9499\n",
            "Epoch 42/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 0.9362 - val_loss: 0.1592 - val_accuracy: 0.9464\n",
            "Epoch 43/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9365 - val_loss: 0.1553 - val_accuracy: 0.9511\n",
            "Epoch 44/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9388 - val_loss: 0.1563 - val_accuracy: 0.9488\n",
            "Epoch 45/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9385 - val_loss: 0.1510 - val_accuracy: 0.9476\n",
            "Epoch 46/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9391 - val_loss: 0.1499 - val_accuracy: 0.9511\n",
            "Epoch 47/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9394 - val_loss: 0.1467 - val_accuracy: 0.9511\n",
            "Epoch 48/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9406 - val_loss: 0.1448 - val_accuracy: 0.9499\n",
            "Epoch 49/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9414 - val_loss: 0.1417 - val_accuracy: 0.9546\n",
            "Epoch 50/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9426 - val_loss: 0.1457 - val_accuracy: 0.9488\n",
            "Epoch 51/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1680 - accuracy: 0.9438 - val_loss: 0.1387 - val_accuracy: 0.9523\n",
            "Epoch 52/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9449 - val_loss: 0.1379 - val_accuracy: 0.9523\n",
            "Epoch 53/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9461 - val_loss: 0.1371 - val_accuracy: 0.9534\n",
            "Epoch 54/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9458 - val_loss: 0.1315 - val_accuracy: 0.9593\n",
            "Epoch 55/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9467 - val_loss: 0.1299 - val_accuracy: 0.9604\n",
            "Epoch 56/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9478 - val_loss: 0.1294 - val_accuracy: 0.9569\n",
            "Epoch 57/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9493 - val_loss: 0.1286 - val_accuracy: 0.9569\n",
            "Epoch 58/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9493 - val_loss: 0.1285 - val_accuracy: 0.9569\n",
            "Epoch 59/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9502 - val_loss: 0.1264 - val_accuracy: 0.9569\n",
            "Epoch 60/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9496 - val_loss: 0.1236 - val_accuracy: 0.9593\n",
            "Epoch 61/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9510 - val_loss: 0.1248 - val_accuracy: 0.9534\n",
            "Epoch 62/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9493 - val_loss: 0.1203 - val_accuracy: 0.9604\n",
            "Epoch 63/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9528 - val_loss: 0.1225 - val_accuracy: 0.9569\n",
            "Epoch 64/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9540 - val_loss: 0.1195 - val_accuracy: 0.9593\n",
            "Epoch 65/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9540 - val_loss: 0.1174 - val_accuracy: 0.9604\n",
            "Epoch 66/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9545 - val_loss: 0.1140 - val_accuracy: 0.9627\n",
            "Epoch 67/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9551 - val_loss: 0.1178 - val_accuracy: 0.9627\n",
            "Epoch 68/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9563 - val_loss: 0.1152 - val_accuracy: 0.9639\n",
            "Epoch 69/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9563 - val_loss: 0.1125 - val_accuracy: 0.9686\n",
            "Epoch 70/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9569 - val_loss: 0.1119 - val_accuracy: 0.9639\n",
            "Epoch 71/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9560 - val_loss: 0.1100 - val_accuracy: 0.9639\n",
            "Epoch 72/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9583 - val_loss: 0.1084 - val_accuracy: 0.9639\n",
            "Epoch 73/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9572 - val_loss: 0.1087 - val_accuracy: 0.9639\n",
            "Epoch 74/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9578 - val_loss: 0.1083 - val_accuracy: 0.9686\n",
            "Epoch 75/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9592 - val_loss: 0.1113 - val_accuracy: 0.9662\n",
            "Epoch 76/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9598 - val_loss: 0.1068 - val_accuracy: 0.9662\n",
            "Epoch 77/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9604 - val_loss: 0.1060 - val_accuracy: 0.9651\n",
            "Epoch 78/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9601 - val_loss: 0.1061 - val_accuracy: 0.9674\n",
            "Epoch 79/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9612 - val_loss: 0.1027 - val_accuracy: 0.9674\n",
            "Epoch 80/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9621 - val_loss: 0.1056 - val_accuracy: 0.9709\n",
            "Epoch 81/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9601 - val_loss: 0.0990 - val_accuracy: 0.9697\n",
            "Epoch 82/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9615 - val_loss: 0.1013 - val_accuracy: 0.9709\n",
            "Epoch 83/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9630 - val_loss: 0.0995 - val_accuracy: 0.9697\n",
            "Epoch 84/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9633 - val_loss: 0.1061 - val_accuracy: 0.9674\n",
            "Epoch 85/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9636 - val_loss: 0.0978 - val_accuracy: 0.9697\n",
            "Epoch 86/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9642 - val_loss: 0.0984 - val_accuracy: 0.9709\n",
            "Epoch 87/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9642 - val_loss: 0.0977 - val_accuracy: 0.9709\n",
            "Epoch 88/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9656 - val_loss: 0.0959 - val_accuracy: 0.9732\n",
            "Epoch 89/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9653 - val_loss: 0.0954 - val_accuracy: 0.9732\n",
            "Epoch 90/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9662 - val_loss: 0.0961 - val_accuracy: 0.9721\n",
            "Epoch 91/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9653 - val_loss: 0.0958 - val_accuracy: 0.9721\n",
            "Epoch 92/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1133 - accuracy: 0.9665 - val_loss: 0.0961 - val_accuracy: 0.9709\n",
            "Epoch 93/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9677 - val_loss: 0.0909 - val_accuracy: 0.9744\n",
            "Epoch 94/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9662 - val_loss: 0.0916 - val_accuracy: 0.9744\n",
            "Epoch 95/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9662 - val_loss: 0.0921 - val_accuracy: 0.9732\n",
            "Epoch 96/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1106 - accuracy: 0.9656 - val_loss: 0.0897 - val_accuracy: 0.9744\n",
            "Epoch 97/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9668 - val_loss: 0.0890 - val_accuracy: 0.9744\n",
            "Epoch 98/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9671 - val_loss: 0.0871 - val_accuracy: 0.9756\n",
            "Epoch 99/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9677 - val_loss: 0.0898 - val_accuracy: 0.9732\n",
            "Epoch 100/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9671 - val_loss: 0.0857 - val_accuracy: 0.9767\n",
            "Epoch 101/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9685 - val_loss: 0.0889 - val_accuracy: 0.9732\n",
            "Epoch 102/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9679 - val_loss: 0.0853 - val_accuracy: 0.9756\n",
            "Epoch 103/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9685 - val_loss: 0.0863 - val_accuracy: 0.9767\n",
            "Epoch 104/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9688 - val_loss: 0.0835 - val_accuracy: 0.9767\n",
            "Epoch 105/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9691 - val_loss: 0.0840 - val_accuracy: 0.9756\n",
            "Epoch 106/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.9691 - val_loss: 0.0840 - val_accuracy: 0.9756\n",
            "Epoch 107/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9677 - val_loss: 0.0825 - val_accuracy: 0.9756\n",
            "Epoch 108/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9697 - val_loss: 0.0795 - val_accuracy: 0.9790\n",
            "Epoch 109/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.9694 - val_loss: 0.0820 - val_accuracy: 0.9779\n",
            "Epoch 110/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9697 - val_loss: 0.0796 - val_accuracy: 0.9779\n",
            "Epoch 111/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9714 - val_loss: 0.0775 - val_accuracy: 0.9790\n",
            "Epoch 112/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.9706 - val_loss: 0.0788 - val_accuracy: 0.9779\n",
            "Epoch 113/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9709 - val_loss: 0.0809 - val_accuracy: 0.9756\n",
            "Epoch 114/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.9714 - val_loss: 0.0772 - val_accuracy: 0.9779\n",
            "Epoch 115/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9703 - val_loss: 0.0787 - val_accuracy: 0.9779\n",
            "Epoch 116/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9709 - val_loss: 0.0750 - val_accuracy: 0.9790\n",
            "Epoch 117/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9706 - val_loss: 0.0763 - val_accuracy: 0.9779\n",
            "Epoch 118/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9700 - val_loss: 0.0785 - val_accuracy: 0.9779\n",
            "Epoch 119/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9735 - val_loss: 0.0730 - val_accuracy: 0.9790\n",
            "Epoch 120/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9717 - val_loss: 0.0754 - val_accuracy: 0.9779\n",
            "Epoch 121/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9732 - val_loss: 0.0767 - val_accuracy: 0.9790\n",
            "Epoch 122/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9729 - val_loss: 0.0740 - val_accuracy: 0.9779\n",
            "Epoch 123/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9726 - val_loss: 0.0740 - val_accuracy: 0.9802\n",
            "Epoch 124/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9735 - val_loss: 0.0720 - val_accuracy: 0.9790\n",
            "Epoch 125/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9729 - val_loss: 0.0751 - val_accuracy: 0.9790\n",
            "Epoch 126/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9735 - val_loss: 0.0707 - val_accuracy: 0.9790\n",
            "Epoch 127/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9735 - val_loss: 0.0700 - val_accuracy: 0.9802\n",
            "Epoch 128/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9749 - val_loss: 0.0707 - val_accuracy: 0.9802\n",
            "Epoch 129/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9732 - val_loss: 0.0679 - val_accuracy: 0.9802\n",
            "Epoch 130/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9732 - val_loss: 0.0712 - val_accuracy: 0.9767\n",
            "Epoch 131/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9732 - val_loss: 0.0676 - val_accuracy: 0.9802\n",
            "Epoch 132/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9749 - val_loss: 0.0690 - val_accuracy: 0.9802\n",
            "Epoch 133/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9749 - val_loss: 0.0685 - val_accuracy: 0.9790\n",
            "Epoch 134/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9755 - val_loss: 0.0690 - val_accuracy: 0.9802\n",
            "Epoch 135/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9752 - val_loss: 0.0699 - val_accuracy: 0.9802\n",
            "Epoch 136/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9758 - val_loss: 0.0672 - val_accuracy: 0.9802\n",
            "Epoch 137/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9741 - val_loss: 0.0663 - val_accuracy: 0.9802\n",
            "Epoch 138/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9755 - val_loss: 0.0686 - val_accuracy: 0.9790\n",
            "Epoch 139/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9755 - val_loss: 0.0662 - val_accuracy: 0.9802\n",
            "Epoch 140/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9758 - val_loss: 0.0675 - val_accuracy: 0.9790\n",
            "Epoch 141/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9758 - val_loss: 0.0658 - val_accuracy: 0.9802\n",
            "Epoch 142/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9770 - val_loss: 0.0677 - val_accuracy: 0.9779\n",
            "Epoch 143/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9764 - val_loss: 0.0618 - val_accuracy: 0.9837\n",
            "Epoch 144/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9770 - val_loss: 0.0634 - val_accuracy: 0.9814\n",
            "Epoch 145/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9767 - val_loss: 0.0637 - val_accuracy: 0.9814\n",
            "Epoch 146/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9767 - val_loss: 0.0638 - val_accuracy: 0.9802\n",
            "Epoch 147/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9781 - val_loss: 0.0599 - val_accuracy: 0.9837\n",
            "Epoch 148/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9773 - val_loss: 0.0628 - val_accuracy: 0.9814\n",
            "Epoch 149/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9761 - val_loss: 0.0615 - val_accuracy: 0.9814\n",
            "Epoch 150/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9764 - val_loss: 0.0604 - val_accuracy: 0.9825\n",
            "Epoch 151/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9761 - val_loss: 0.0618 - val_accuracy: 0.9802\n",
            "Epoch 152/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9787 - val_loss: 0.0598 - val_accuracy: 0.9825\n",
            "Epoch 153/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9787 - val_loss: 0.0619 - val_accuracy: 0.9802\n",
            "Epoch 154/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9779 - val_loss: 0.0606 - val_accuracy: 0.9814\n",
            "Epoch 155/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9773 - val_loss: 0.0583 - val_accuracy: 0.9825\n",
            "Epoch 156/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9790 - val_loss: 0.0599 - val_accuracy: 0.9825\n",
            "Epoch 157/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9796 - val_loss: 0.0590 - val_accuracy: 0.9825\n",
            "Epoch 158/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9787 - val_loss: 0.0577 - val_accuracy: 0.9825\n",
            "Epoch 159/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9784 - val_loss: 0.0590 - val_accuracy: 0.9814\n",
            "Epoch 160/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9799 - val_loss: 0.0615 - val_accuracy: 0.9767\n",
            "Epoch 161/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9787 - val_loss: 0.0592 - val_accuracy: 0.9814\n",
            "Epoch 162/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9796 - val_loss: 0.0554 - val_accuracy: 0.9849\n",
            "Epoch 163/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9793 - val_loss: 0.0555 - val_accuracy: 0.9837\n",
            "Epoch 164/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9793 - val_loss: 0.0550 - val_accuracy: 0.9837\n",
            "Epoch 165/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9799 - val_loss: 0.0565 - val_accuracy: 0.9825\n",
            "Epoch 166/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9802 - val_loss: 0.0627 - val_accuracy: 0.9779\n",
            "Epoch 167/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9796 - val_loss: 0.0554 - val_accuracy: 0.9825\n",
            "Epoch 168/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9796 - val_loss: 0.0555 - val_accuracy: 0.9837\n",
            "Epoch 169/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9799 - val_loss: 0.0529 - val_accuracy: 0.9849\n",
            "Epoch 170/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9802 - val_loss: 0.0533 - val_accuracy: 0.9837\n",
            "Epoch 171/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9796 - val_loss: 0.0561 - val_accuracy: 0.9802\n",
            "Epoch 172/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9802 - val_loss: 0.0528 - val_accuracy: 0.9849\n",
            "Epoch 173/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9805 - val_loss: 0.0536 - val_accuracy: 0.9860\n",
            "Epoch 174/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9814 - val_loss: 0.0538 - val_accuracy: 0.9825\n",
            "Epoch 175/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9811 - val_loss: 0.0534 - val_accuracy: 0.9860\n",
            "Epoch 176/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9802 - val_loss: 0.0531 - val_accuracy: 0.9837\n",
            "Epoch 177/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9819 - val_loss: 0.0511 - val_accuracy: 0.9837\n",
            "Epoch 178/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9816 - val_loss: 0.0534 - val_accuracy: 0.9837\n",
            "Epoch 179/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9816 - val_loss: 0.0510 - val_accuracy: 0.9849\n",
            "Epoch 180/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9819 - val_loss: 0.0536 - val_accuracy: 0.9790\n",
            "Epoch 181/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9808 - val_loss: 0.0497 - val_accuracy: 0.9849\n",
            "Epoch 182/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9816 - val_loss: 0.0490 - val_accuracy: 0.9860\n",
            "Epoch 183/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9819 - val_loss: 0.0504 - val_accuracy: 0.9860\n",
            "Epoch 184/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9811 - val_loss: 0.0514 - val_accuracy: 0.9860\n",
            "Epoch 185/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9828 - val_loss: 0.0488 - val_accuracy: 0.9860\n",
            "Epoch 186/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9822 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
            "Epoch 187/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9825 - val_loss: 0.0566 - val_accuracy: 0.9814\n",
            "Epoch 188/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9819 - val_loss: 0.0504 - val_accuracy: 0.9837\n",
            "Epoch 189/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9825 - val_loss: 0.0510 - val_accuracy: 0.9825\n",
            "Epoch 190/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9834 - val_loss: 0.0478 - val_accuracy: 0.9860\n",
            "Epoch 191/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9828 - val_loss: 0.0472 - val_accuracy: 0.9872\n",
            "Epoch 192/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9831 - val_loss: 0.0493 - val_accuracy: 0.9825\n",
            "Epoch 193/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9828 - val_loss: 0.0461 - val_accuracy: 0.9872\n",
            "Epoch 194/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9828 - val_loss: 0.0472 - val_accuracy: 0.9872\n",
            "Epoch 195/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9828 - val_loss: 0.0470 - val_accuracy: 0.9860\n",
            "Epoch 196/500\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9831 - val_loss: 0.0471 - val_accuracy: 0.9860\n",
            "Epoch 197/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9837 - val_loss: 0.0452 - val_accuracy: 0.9884\n",
            "Epoch 198/500\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9834 - val_loss: 0.0453 - val_accuracy: 0.9872\n",
            "Epoch 199/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0593 - accuracy: 0.9831 - val_loss: 0.0453 - val_accuracy: 0.9872\n",
            "Epoch 200/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9840 - val_loss: 0.0446 - val_accuracy: 0.9895\n",
            "Epoch 201/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9834 - val_loss: 0.0442 - val_accuracy: 0.9895\n",
            "Epoch 202/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9851 - val_loss: 0.0452 - val_accuracy: 0.9860\n",
            "Epoch 203/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9840 - val_loss: 0.0447 - val_accuracy: 0.9884\n",
            "Epoch 204/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9846 - val_loss: 0.0447 - val_accuracy: 0.9872\n",
            "Epoch 205/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9840 - val_loss: 0.0452 - val_accuracy: 0.9860\n",
            "Epoch 206/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9837 - val_loss: 0.0454 - val_accuracy: 0.9872\n",
            "Epoch 207/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9846 - val_loss: 0.0454 - val_accuracy: 0.9872\n",
            "Epoch 208/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9846 - val_loss: 0.0449 - val_accuracy: 0.9872\n",
            "Epoch 209/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9840 - val_loss: 0.0429 - val_accuracy: 0.9895\n",
            "Epoch 210/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9843 - val_loss: 0.0427 - val_accuracy: 0.9895\n",
            "Epoch 211/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9848 - val_loss: 0.0429 - val_accuracy: 0.9884\n",
            "Epoch 212/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9846 - val_loss: 0.0441 - val_accuracy: 0.9872\n",
            "Epoch 213/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 0.9834 - val_loss: 0.0453 - val_accuracy: 0.9860\n",
            "Epoch 214/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9834 - val_loss: 0.0413 - val_accuracy: 0.9895\n",
            "Epoch 215/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9846 - val_loss: 0.0424 - val_accuracy: 0.9895\n",
            "Epoch 216/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.0436 - val_accuracy: 0.9872\n",
            "Epoch 217/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9840 - val_loss: 0.0429 - val_accuracy: 0.9884\n",
            "Epoch 218/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9846 - val_loss: 0.0413 - val_accuracy: 0.9895\n",
            "Epoch 219/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9848 - val_loss: 0.0419 - val_accuracy: 0.9895\n",
            "Epoch 220/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9857 - val_loss: 0.0468 - val_accuracy: 0.9860\n",
            "Epoch 221/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.0406 - val_accuracy: 0.9895\n",
            "Epoch 222/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9843 - val_loss: 0.0419 - val_accuracy: 0.9895\n",
            "Epoch 223/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9860 - val_loss: 0.0443 - val_accuracy: 0.9849\n",
            "Epoch 224/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9848 - val_loss: 0.0411 - val_accuracy: 0.9895\n",
            "Epoch 225/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9840 - val_loss: 0.0416 - val_accuracy: 0.9884\n",
            "Epoch 226/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9851 - val_loss: 0.0397 - val_accuracy: 0.9895\n",
            "Epoch 227/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9851 - val_loss: 0.0400 - val_accuracy: 0.9895\n",
            "Epoch 228/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9866 - val_loss: 0.0397 - val_accuracy: 0.9895\n",
            "Epoch 229/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9857 - val_loss: 0.0419 - val_accuracy: 0.9872\n",
            "Epoch 230/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9857 - val_loss: 0.0403 - val_accuracy: 0.9919\n",
            "Epoch 231/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9869 - val_loss: 0.0416 - val_accuracy: 0.9884\n",
            "Epoch 232/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9860 - val_loss: 0.0392 - val_accuracy: 0.9895\n",
            "Epoch 233/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9863 - val_loss: 0.0386 - val_accuracy: 0.9895\n",
            "Epoch 234/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9848 - val_loss: 0.0382 - val_accuracy: 0.9895\n",
            "Epoch 235/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9863 - val_loss: 0.0383 - val_accuracy: 0.9895\n",
            "Epoch 236/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9863 - val_loss: 0.0383 - val_accuracy: 0.9907\n",
            "Epoch 237/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9857 - val_loss: 0.0378 - val_accuracy: 0.9895\n",
            "Epoch 238/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9857 - val_loss: 0.0380 - val_accuracy: 0.9907\n",
            "Epoch 239/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.0373 - val_accuracy: 0.9895\n",
            "Epoch 240/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9866 - val_loss: 0.0380 - val_accuracy: 0.9907\n",
            "Epoch 241/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9866 - val_loss: 0.0383 - val_accuracy: 0.9907\n",
            "Epoch 242/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9860 - val_loss: 0.0385 - val_accuracy: 0.9907\n",
            "Epoch 243/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9869 - val_loss: 0.0376 - val_accuracy: 0.9930\n",
            "Epoch 244/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9872 - val_loss: 0.0375 - val_accuracy: 0.9907\n",
            "Epoch 245/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.0366 - val_accuracy: 0.9919\n",
            "Epoch 246/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.0403 - val_accuracy: 0.9895\n",
            "Epoch 247/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9872 - val_loss: 0.0397 - val_accuracy: 0.9895\n",
            "Epoch 248/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9866 - val_loss: 0.0406 - val_accuracy: 0.9895\n",
            "Epoch 249/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9869 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
            "Epoch 250/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9872 - val_loss: 0.0379 - val_accuracy: 0.9907\n",
            "Epoch 251/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.9878 - val_loss: 0.0362 - val_accuracy: 0.9907\n",
            "Epoch 252/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.0356 - val_accuracy: 0.9907\n",
            "Epoch 253/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.0364 - val_accuracy: 0.9907\n",
            "Epoch 254/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9866 - val_loss: 0.0372 - val_accuracy: 0.9919\n",
            "Epoch 255/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9875 - val_loss: 0.0354 - val_accuracy: 0.9919\n",
            "Epoch 256/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9875 - val_loss: 0.0352 - val_accuracy: 0.9930\n",
            "Epoch 257/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9886 - val_loss: 0.0356 - val_accuracy: 0.9930\n",
            "Epoch 258/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9886 - val_loss: 0.0357 - val_accuracy: 0.9907\n",
            "Epoch 259/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9863 - val_loss: 0.0371 - val_accuracy: 0.9919\n",
            "Epoch 260/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9878 - val_loss: 0.0362 - val_accuracy: 0.9907\n",
            "Epoch 261/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9892 - val_loss: 0.0358 - val_accuracy: 0.9907\n",
            "Epoch 262/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9875 - val_loss: 0.0343 - val_accuracy: 0.9919\n",
            "Epoch 263/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9886 - val_loss: 0.0361 - val_accuracy: 0.9930\n",
            "Epoch 264/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9878 - val_loss: 0.0340 - val_accuracy: 0.9919\n",
            "Epoch 265/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9886 - val_loss: 0.0387 - val_accuracy: 0.9895\n",
            "Epoch 266/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9875 - val_loss: 0.0365 - val_accuracy: 0.9930\n",
            "Epoch 267/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9866 - val_loss: 0.0336 - val_accuracy: 0.9919\n",
            "Epoch 268/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9872 - val_loss: 0.0344 - val_accuracy: 0.9942\n",
            "Epoch 269/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9886 - val_loss: 0.0342 - val_accuracy: 0.9919\n",
            "Epoch 270/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9886 - val_loss: 0.0332 - val_accuracy: 0.9919\n",
            "Epoch 271/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9886 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
            "Epoch 272/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9883 - val_loss: 0.0356 - val_accuracy: 0.9919\n",
            "Epoch 273/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9886 - val_loss: 0.0341 - val_accuracy: 0.9930\n",
            "Epoch 274/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9883 - val_loss: 0.0345 - val_accuracy: 0.9930\n",
            "Epoch 275/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: 0.0335 - val_accuracy: 0.9942\n",
            "Epoch 276/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9889 - val_loss: 0.0347 - val_accuracy: 0.9907\n",
            "Epoch 277/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9889 - val_loss: 0.0333 - val_accuracy: 0.9942\n",
            "Epoch 278/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9889 - val_loss: 0.0330 - val_accuracy: 0.9942\n",
            "Epoch 279/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9892 - val_loss: 0.0329 - val_accuracy: 0.9942\n",
            "Epoch 280/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 0.0321 - val_accuracy: 0.9942\n",
            "Epoch 281/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9892 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
            "Epoch 282/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9895 - val_loss: 0.0380 - val_accuracy: 0.9907\n",
            "Epoch 283/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9881 - val_loss: 0.0319 - val_accuracy: 0.9942\n",
            "Epoch 284/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9901 - val_loss: 0.0326 - val_accuracy: 0.9942\n",
            "Epoch 285/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9898 - val_loss: 0.0318 - val_accuracy: 0.9942\n",
            "Epoch 286/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9886 - val_loss: 0.0336 - val_accuracy: 0.9919\n",
            "Epoch 287/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9901 - val_loss: 0.0336 - val_accuracy: 0.9895\n",
            "Epoch 288/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9878 - val_loss: 0.0316 - val_accuracy: 0.9930\n",
            "Epoch 289/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9892 - val_loss: 0.0316 - val_accuracy: 0.9942\n",
            "Epoch 290/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9898 - val_loss: 0.0349 - val_accuracy: 0.9907\n",
            "Epoch 291/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9883 - val_loss: 0.0308 - val_accuracy: 0.9942\n",
            "Epoch 292/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9895 - val_loss: 0.0308 - val_accuracy: 0.9942\n",
            "Epoch 293/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9904 - val_loss: 0.0321 - val_accuracy: 0.9930\n",
            "Epoch 294/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9907 - val_loss: 0.0313 - val_accuracy: 0.9930\n",
            "Epoch 295/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9895 - val_loss: 0.0307 - val_accuracy: 0.9942\n",
            "Epoch 296/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9904 - val_loss: 0.0313 - val_accuracy: 0.9942\n",
            "Epoch 297/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9904 - val_loss: 0.0314 - val_accuracy: 0.9942\n",
            "Epoch 298/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9904 - val_loss: 0.0302 - val_accuracy: 0.9942\n",
            "Epoch 299/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9898 - val_loss: 0.0317 - val_accuracy: 0.9942\n",
            "Epoch 300/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.0309 - val_accuracy: 0.9942\n",
            "Epoch 301/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9904 - val_loss: 0.0353 - val_accuracy: 0.9919\n",
            "Epoch 302/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9895 - val_loss: 0.0307 - val_accuracy: 0.9942\n",
            "Epoch 303/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9898 - val_loss: 0.0320 - val_accuracy: 0.9919\n",
            "Epoch 304/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9901 - val_loss: 0.0302 - val_accuracy: 0.9942\n",
            "Epoch 305/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9910 - val_loss: 0.0296 - val_accuracy: 0.9930\n",
            "Epoch 306/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9910 - val_loss: 0.0304 - val_accuracy: 0.9942\n",
            "Epoch 307/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.0310 - val_accuracy: 0.9930\n",
            "Epoch 308/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9895 - val_loss: 0.0299 - val_accuracy: 0.9942\n",
            "Epoch 309/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9904 - val_loss: 0.0336 - val_accuracy: 0.9919\n",
            "Epoch 310/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9910 - val_loss: 0.0298 - val_accuracy: 0.9942\n",
            "Epoch 311/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9904 - val_loss: 0.0295 - val_accuracy: 0.9930\n",
            "Epoch 312/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9910 - val_loss: 0.0301 - val_accuracy: 0.9942\n",
            "Epoch 313/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9901 - val_loss: 0.0289 - val_accuracy: 0.9942\n",
            "Epoch 314/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9898 - val_loss: 0.0294 - val_accuracy: 0.9942\n",
            "Epoch 315/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9895 - val_loss: 0.0287 - val_accuracy: 0.9942\n",
            "Epoch 316/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9901 - val_loss: 0.0288 - val_accuracy: 0.9942\n",
            "Epoch 317/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9910 - val_loss: 0.0288 - val_accuracy: 0.9942\n",
            "Epoch 318/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9916 - val_loss: 0.0294 - val_accuracy: 0.9942\n",
            "Epoch 319/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9910 - val_loss: 0.0312 - val_accuracy: 0.9919\n",
            "Epoch 320/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9901 - val_loss: 0.0287 - val_accuracy: 0.9942\n",
            "Epoch 321/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9901 - val_loss: 0.0284 - val_accuracy: 0.9942\n",
            "Epoch 322/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9907 - val_loss: 0.0288 - val_accuracy: 0.9942\n",
            "Epoch 323/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9907 - val_loss: 0.0301 - val_accuracy: 0.9930\n",
            "Epoch 324/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9910 - val_loss: 0.0286 - val_accuracy: 0.9942\n",
            "Epoch 325/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9913 - val_loss: 0.0303 - val_accuracy: 0.9919\n",
            "Epoch 326/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9889 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
            "Epoch 327/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9907 - val_loss: 0.0288 - val_accuracy: 0.9942\n",
            "Epoch 328/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9913 - val_loss: 0.0290 - val_accuracy: 0.9942\n",
            "Epoch 329/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9910 - val_loss: 0.0283 - val_accuracy: 0.9942\n",
            "Epoch 330/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9910 - val_loss: 0.0288 - val_accuracy: 0.9942\n",
            "Epoch 331/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9910 - val_loss: 0.0303 - val_accuracy: 0.9919\n",
            "Epoch 332/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9904 - val_loss: 0.0280 - val_accuracy: 0.9942\n",
            "Epoch 333/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9913 - val_loss: 0.0303 - val_accuracy: 0.9930\n",
            "Epoch 334/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9910 - val_loss: 0.0298 - val_accuracy: 0.9930\n",
            "Epoch 335/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9910 - val_loss: 0.0291 - val_accuracy: 0.9930\n",
            "Epoch 336/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 0.0284 - val_accuracy: 0.9942\n",
            "Epoch 337/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.0275 - val_accuracy: 0.9942\n",
            "Epoch 338/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9913 - val_loss: 0.0277 - val_accuracy: 0.9942\n",
            "Epoch 339/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9913 - val_loss: 0.0280 - val_accuracy: 0.9942\n",
            "Epoch 340/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9913 - val_loss: 0.0278 - val_accuracy: 0.9942\n",
            "Epoch 341/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9913 - val_loss: 0.0287 - val_accuracy: 0.9930\n",
            "Epoch 342/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
            "Epoch 343/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9916 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
            "Epoch 344/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9910 - val_loss: 0.0280 - val_accuracy: 0.9942\n",
            "Epoch 345/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9913 - val_loss: 0.0280 - val_accuracy: 0.9942\n",
            "Epoch 346/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9916 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
            "Epoch 347/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9913 - val_loss: 0.0276 - val_accuracy: 0.9942\n",
            "Epoch 348/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9916 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
            "Epoch 349/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9918 - val_loss: 0.0265 - val_accuracy: 0.9942\n",
            "Epoch 350/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9913 - val_loss: 0.0267 - val_accuracy: 0.9942\n",
            "Epoch 351/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
            "Epoch 352/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9921 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
            "Epoch 353/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 0.0271 - val_accuracy: 0.9942\n",
            "Epoch 354/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9921 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
            "Epoch 355/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9904 - val_loss: 0.0275 - val_accuracy: 0.9942\n",
            "Epoch 356/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9921 - val_loss: 0.0284 - val_accuracy: 0.9930\n",
            "Epoch 357/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9918 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
            "Epoch 358/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9913 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
            "Epoch 359/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9916 - val_loss: 0.0292 - val_accuracy: 0.9930\n",
            "Epoch 360/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9918 - val_loss: 0.0276 - val_accuracy: 0.9930\n",
            "Epoch 361/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9910 - val_loss: 0.0259 - val_accuracy: 0.9942\n",
            "Epoch 362/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9913 - val_loss: 0.0260 - val_accuracy: 0.9942\n",
            "Epoch 363/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9918 - val_loss: 0.0275 - val_accuracy: 0.9942\n",
            "Epoch 364/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9918 - val_loss: 0.0261 - val_accuracy: 0.9942\n",
            "Epoch 365/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
            "Epoch 366/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9924 - val_loss: 0.0271 - val_accuracy: 0.9942\n",
            "Epoch 367/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9916 - val_loss: 0.0266 - val_accuracy: 0.9942\n",
            "Epoch 368/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9921 - val_loss: 0.0263 - val_accuracy: 0.9942\n",
            "Epoch 369/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.0255 - val_accuracy: 0.9942\n",
            "Epoch 370/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9921 - val_loss: 0.0254 - val_accuracy: 0.9942\n",
            "Epoch 371/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 0.9918 - val_loss: 0.0274 - val_accuracy: 0.9953\n",
            "Epoch 372/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9921 - val_loss: 0.0269 - val_accuracy: 0.9942\n",
            "Epoch 373/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9921 - val_loss: 0.0280 - val_accuracy: 0.9930\n",
            "Epoch 374/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9916 - val_loss: 0.0270 - val_accuracy: 0.9942\n",
            "Epoch 375/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 0.0255 - val_accuracy: 0.9942\n",
            "Epoch 376/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9918 - val_loss: 0.0255 - val_accuracy: 0.9942\n",
            "Epoch 377/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9921 - val_loss: 0.0261 - val_accuracy: 0.9942\n",
            "Epoch 378/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9916 - val_loss: 0.0273 - val_accuracy: 0.9942\n",
            "Epoch 379/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9921 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
            "Epoch 380/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9918 - val_loss: 0.0260 - val_accuracy: 0.9953\n",
            "Epoch 381/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9918 - val_loss: 0.0281 - val_accuracy: 0.9930\n",
            "Epoch 382/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
            "Epoch 383/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9921 - val_loss: 0.0251 - val_accuracy: 0.9942\n",
            "Epoch 384/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9924 - val_loss: 0.0248 - val_accuracy: 0.9942\n",
            "Epoch 385/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9924 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
            "Epoch 386/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 0.0256 - val_accuracy: 0.9953\n",
            "Epoch 387/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9921 - val_loss: 0.0252 - val_accuracy: 0.9942\n",
            "Epoch 388/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9916 - val_loss: 0.0261 - val_accuracy: 0.9942\n",
            "Epoch 389/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9924 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
            "Epoch 390/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9918 - val_loss: 0.0247 - val_accuracy: 0.9942\n",
            "Epoch 391/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9921 - val_loss: 0.0247 - val_accuracy: 0.9942\n",
            "Epoch 392/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9924 - val_loss: 0.0270 - val_accuracy: 0.9942\n",
            "Epoch 393/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9916 - val_loss: 0.0242 - val_accuracy: 0.9942\n",
            "Epoch 394/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9921 - val_loss: 0.0246 - val_accuracy: 0.9942\n",
            "Epoch 395/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9927 - val_loss: 0.0245 - val_accuracy: 0.9942\n",
            "Epoch 396/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9921 - val_loss: 0.0247 - val_accuracy: 0.9942\n",
            "Epoch 397/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9918 - val_loss: 0.0242 - val_accuracy: 0.9942\n",
            "Epoch 398/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9918 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
            "Epoch 399/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9921 - val_loss: 0.0243 - val_accuracy: 0.9942\n",
            "Epoch 400/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.0282 - val_accuracy: 0.9930\n",
            "Epoch 401/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.0245 - val_accuracy: 0.9942\n",
            "Epoch 402/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9921 - val_loss: 0.0264 - val_accuracy: 0.9942\n",
            "Epoch 403/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.0237 - val_accuracy: 0.9942\n",
            "Epoch 404/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0328 - accuracy: 0.9924 - val_loss: 0.0245 - val_accuracy: 0.9953\n",
            "Epoch 405/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9921 - val_loss: 0.0243 - val_accuracy: 0.9942\n",
            "Epoch 406/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9924 - val_loss: 0.0239 - val_accuracy: 0.9942\n",
            "Epoch 407/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 0.0235 - val_accuracy: 0.9942\n",
            "Epoch 408/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9927 - val_loss: 0.0237 - val_accuracy: 0.9942\n",
            "Epoch 409/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9921 - val_loss: 0.0254 - val_accuracy: 0.9953\n",
            "Epoch 410/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9924 - val_loss: 0.0236 - val_accuracy: 0.9942\n",
            "Epoch 411/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9921 - val_loss: 0.0237 - val_accuracy: 0.9942\n",
            "Epoch 412/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9924 - val_loss: 0.0239 - val_accuracy: 0.9953\n",
            "Epoch 413/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 0.0232 - val_accuracy: 0.9942\n",
            "Epoch 414/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9924 - val_loss: 0.0257 - val_accuracy: 0.9942\n",
            "Epoch 415/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9924 - val_loss: 0.0240 - val_accuracy: 0.9953\n",
            "Epoch 416/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9924 - val_loss: 0.0243 - val_accuracy: 0.9953\n",
            "Epoch 417/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0253 - val_accuracy: 0.9942\n",
            "Epoch 418/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9927 - val_loss: 0.0238 - val_accuracy: 0.9953\n",
            "Epoch 419/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9924 - val_loss: 0.0243 - val_accuracy: 0.9953\n",
            "Epoch 420/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9924 - val_loss: 0.0236 - val_accuracy: 0.9942\n",
            "Epoch 421/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 0.0231 - val_accuracy: 0.9942\n",
            "Epoch 422/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9924 - val_loss: 0.0232 - val_accuracy: 0.9953\n",
            "Epoch 423/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9924 - val_loss: 0.0234 - val_accuracy: 0.9953\n",
            "Epoch 424/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9918 - val_loss: 0.0234 - val_accuracy: 0.9953\n",
            "Epoch 425/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9924 - val_loss: 0.0233 - val_accuracy: 0.9953\n",
            "Epoch 426/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9924 - val_loss: 0.0245 - val_accuracy: 0.9953\n",
            "Epoch 427/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 0.0231 - val_accuracy: 0.9953\n",
            "Epoch 428/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 0.0235 - val_accuracy: 0.9953\n",
            "Epoch 429/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 0.0231 - val_accuracy: 0.9953\n",
            "Epoch 430/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9930 - val_loss: 0.0226 - val_accuracy: 0.9942\n",
            "Epoch 431/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9921 - val_loss: 0.0234 - val_accuracy: 0.9942\n",
            "Epoch 432/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9921 - val_loss: 0.0244 - val_accuracy: 0.9953\n",
            "Epoch 433/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9924 - val_loss: 0.0223 - val_accuracy: 0.9942\n",
            "Epoch 434/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9927 - val_loss: 0.0226 - val_accuracy: 0.9942\n",
            "Epoch 435/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9921 - val_loss: 0.0226 - val_accuracy: 0.9942\n",
            "Epoch 436/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9927 - val_loss: 0.0239 - val_accuracy: 0.9953\n",
            "Epoch 437/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.0235 - val_accuracy: 0.9953\n",
            "Epoch 438/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9921 - val_loss: 0.0250 - val_accuracy: 0.9942\n",
            "Epoch 439/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9924 - val_loss: 0.0221 - val_accuracy: 0.9942\n",
            "Epoch 440/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9924 - val_loss: 0.0220 - val_accuracy: 0.9942\n",
            "Epoch 441/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 0.0253 - val_accuracy: 0.9942\n",
            "Epoch 442/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 0.9927 - val_loss: 0.0239 - val_accuracy: 0.9953\n",
            "Epoch 443/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9927 - val_loss: 0.0232 - val_accuracy: 0.9953\n",
            "Epoch 444/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 0.0224 - val_accuracy: 0.9953\n",
            "Epoch 445/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 0.0238 - val_accuracy: 0.9953\n",
            "Epoch 446/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 0.0227 - val_accuracy: 0.9953\n",
            "Epoch 447/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9930 - val_loss: 0.0246 - val_accuracy: 0.9942\n",
            "Epoch 448/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9930 - val_loss: 0.0234 - val_accuracy: 0.9953\n",
            "Epoch 449/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9924 - val_loss: 0.0221 - val_accuracy: 0.9953\n",
            "Epoch 450/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9927 - val_loss: 0.0239 - val_accuracy: 0.9942\n",
            "Epoch 451/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9924 - val_loss: 0.0227 - val_accuracy: 0.9953\n",
            "Epoch 452/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9930 - val_loss: 0.0224 - val_accuracy: 0.9953\n",
            "Epoch 453/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9930 - val_loss: 0.0254 - val_accuracy: 0.9942\n",
            "Epoch 454/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9927 - val_loss: 0.0219 - val_accuracy: 0.9953\n",
            "Epoch 455/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9930 - val_loss: 0.0227 - val_accuracy: 0.9953\n",
            "Epoch 456/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9930 - val_loss: 0.0232 - val_accuracy: 0.9953\n",
            "Epoch 457/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9930 - val_loss: 0.0247 - val_accuracy: 0.9942\n",
            "Epoch 458/500\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9930 - val_loss: 0.0215 - val_accuracy: 0.9942\n",
            "Epoch 459/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9930 - val_loss: 0.0221 - val_accuracy: 0.9953\n",
            "Epoch 460/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9933 - val_loss: 0.0215 - val_accuracy: 0.9942\n",
            "Epoch 461/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9930 - val_loss: 0.0222 - val_accuracy: 0.9953\n",
            "Epoch 462/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9930 - val_loss: 0.0227 - val_accuracy: 0.9953\n",
            "Epoch 463/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9936 - val_loss: 0.0260 - val_accuracy: 0.9930\n",
            "Epoch 464/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9921 - val_loss: 0.0232 - val_accuracy: 0.9953\n",
            "Epoch 465/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9939 - val_loss: 0.0216 - val_accuracy: 0.9953\n",
            "Epoch 466/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9927 - val_loss: 0.0247 - val_accuracy: 0.9942\n",
            "Epoch 467/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.0219 - val_accuracy: 0.9953\n",
            "Epoch 468/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.0213 - val_accuracy: 0.9953\n",
            "Epoch 469/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.0228 - val_accuracy: 0.9953\n",
            "Epoch 470/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9930 - val_loss: 0.0220 - val_accuracy: 0.9953\n",
            "Epoch 471/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9930 - val_loss: 0.0213 - val_accuracy: 0.9953\n",
            "Epoch 472/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9933 - val_loss: 0.0220 - val_accuracy: 0.9953\n",
            "Epoch 473/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9933 - val_loss: 0.0229 - val_accuracy: 0.9953\n",
            "Epoch 474/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9927 - val_loss: 0.0226 - val_accuracy: 0.9953\n",
            "Epoch 475/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9930 - val_loss: 0.0209 - val_accuracy: 0.9953\n",
            "Epoch 476/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9927 - val_loss: 0.0214 - val_accuracy: 0.9953\n",
            "Epoch 477/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 0.0234 - val_accuracy: 0.9942\n",
            "Epoch 478/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9936 - val_loss: 0.0230 - val_accuracy: 0.9953\n",
            "Epoch 479/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9936 - val_loss: 0.0209 - val_accuracy: 0.9953\n",
            "Epoch 480/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9930 - val_loss: 0.0221 - val_accuracy: 0.9953\n",
            "Epoch 481/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9939 - val_loss: 0.0246 - val_accuracy: 0.9942\n",
            "Epoch 482/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.0255 - val_accuracy: 0.9942\n",
            "Epoch 483/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9930 - val_loss: 0.0220 - val_accuracy: 0.9953\n",
            "Epoch 484/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9930 - val_loss: 0.0239 - val_accuracy: 0.9942\n",
            "Epoch 485/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 0.0216 - val_accuracy: 0.9953\n",
            "Epoch 486/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9930 - val_loss: 0.0230 - val_accuracy: 0.9953\n",
            "Epoch 487/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9930 - val_loss: 0.0206 - val_accuracy: 0.9942\n",
            "Epoch 488/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9953\n",
            "Epoch 489/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9933 - val_loss: 0.0223 - val_accuracy: 0.9953\n",
            "Epoch 490/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 0.0210 - val_accuracy: 0.9953\n",
            "Epoch 491/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9936 - val_loss: 0.0224 - val_accuracy: 0.9953\n",
            "Epoch 492/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9939 - val_loss: 0.0219 - val_accuracy: 0.9953\n",
            "Epoch 493/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.0208 - val_accuracy: 0.9953\n",
            "Epoch 494/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0267 - val_accuracy: 0.9930\n",
            "Epoch 495/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9939 - val_loss: 0.0227 - val_accuracy: 0.9953\n",
            "Epoch 496/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 0.0204 - val_accuracy: 0.9953\n",
            "Epoch 497/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 0.0222 - val_accuracy: 0.9953\n",
            "Epoch 498/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9936 - val_loss: 0.0214 - val_accuracy: 0.9953\n",
            "Epoch 499/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9936 - val_loss: 0.0203 - val_accuracy: 0.9953\n",
            "Epoch 500/500\n",
            "108/108 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9942 - val_loss: 0.0212 - val_accuracy: 0.9953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "8AUybfkL0tJG",
        "outputId": "410c6a28-3e4f-4557-fdce-a47325ae22c9"
      },
      "source": [
        "model.evaluate(\n",
        "    testing_dataset, \n",
        "    to_categorical(testing_labels)\n",
        ")\n",
        "\n",
        "# Graphing the History\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs= range(1,len(loss)+1)\n",
        "\n",
        "plt.plot(epochs, loss, 'g.', label= 'Training loss')\n",
        "plt.plot(epochs, val_loss, 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend() \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 0.9907\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}